import os
import shutil as sh
import csv


def process_one_line_v2(line):
    if 'Main' in line:
        indmain = line.index('Main')
        rawstr = line[indmain + 4:].strip()
        ind2 = rawstr.index(' ')
        finalstr = rawstr[:ind2]

    if finalstr == '' or finalstr == '???\n':
        finalstr = None
    elif finalstr[-1] == '\n' and finalstr != '???\n':
        finalstr = finalstr[:-1]

    if finalstr == 'PREFIX':
        finalstr = 'REPNE'
    elif finalstr == 'POPFD':
        finalstr = 'POPF'
    elif finalstr == 'POPFD':
        finalstr = 'POPF'
    elif finalstr == 'PUSHFD':
        finalstr = 'PUSHF'
    elif finalstr == 'PUSHAD':
        finalstr = 'PUSHF'

    return finalstr


def process_one_line_v3(line, list_opcode):
    finalstr = [opcode for opcode in list_opcode if opcode in line.split()]
    if len(finalstr) == 0:
        res = None
    elif len(finalstr) == 1:
        res = finalstr[0]
    else:
        if finalstr[0] == 'REP' or finalstr[0] == 'LOCK' or finalstr[0] == 'REPNE' or finalstr[0] == 'REPE':
            res = finalstr[1]
        elif finalstr[1] == 'REP' or finalstr[1] == 'LOCK' or finalstr[1] == 'REPNE' or finalstr[0] == 'REPE':
            res = finalstr[0]
        else:
            res = finalstr[0]
        print(res)

    return res


def process_one_line(line):
    count = 0
    target = []
    for char in line:
        if char == '\t':
            count = count + 1
        if count == 2 and char != ' ':
            target.append(char)
        if count == 2 and char == ' ':
            break
    finalstr = ''.join(target[1:])

    if finalstr == '' or finalstr == '???\n':
        finalstr = None
    elif finalstr[-1] == '\n' and finalstr != '???\n':
        finalstr = finalstr[:-1]

    if finalstr == 'PREFIX':
        finalstr = 'REPNE'
    elif finalstr == 'POPFD':
        finalstr = 'POPF'
    elif finalstr == 'POPFD':
        finalstr = 'POPF'
    elif finalstr == 'PUSHFD':
        finalstr = 'PUSHF'
    elif finalstr == 'PUSHAD':
        finalstr = 'PUSHF'

    return finalstr


def process_incomplete_sequence(sequence, num_of_line_to_gather):
    i = 0
    print('incomplete_sequence_len = ' + str(len(sequence)))
    while not len(sequence) == num_of_line_to_gather:
        sequence.append(sequence[i])
        i = i + 1
    return sequence


def parse(raw_runtrace_file):
    # full opcode dictionary number token mapping
    opcodelistdir = 'E:\\All_code\\Datasets\\fullRawOpCodeList.txt'
    with open(opcodelistdir, 'r') as file:
        list_opcode = [opcodes[:-1] for opcodes in file]
    num_of_line_to_gather = 1000
    start_identifier = 'Run trace stopped'
    line_counter_to_gather = 0
    flag = False
    all_dataset = []
    instance = []
    program_index_all = 0
    index_set_completely_gathered = []
    complet_num = 0
    with open(raw_runtrace_file, 'r', encoding='latin-1') as file:
        for cnt, line in enumerate(file):
            if start_identifier in line:
                program_index_all = program_index_all + 1
                flag = True
                instance = []
                line_counter_to_gather = 0
            elif flag:
                opcode = process_one_line_v3(line, list_opcode)
                if opcode is not None:
                    instance.append(opcode)
                    line_counter_to_gather = line_counter_to_gather + 1
            if line_counter_to_gather == num_of_line_to_gather:
                flag = False
                all_dataset.append(instance)
                line_counter_to_gather = 0
                index_set_completely_gathered.append(program_index_all)
                complet_num = complet_num + 1
                print('sequence_completed : ' + str(complet_num))
            elif 'Process terminated, exit code' in line:
                flag = False
                if len(instance) > 900:
                    p_instance = process_incomplete_sequence(instance, num_of_line_to_gather)
                    all_dataset.append(p_instance)
                line_counter_to_gather = 0
                index_set_completely_gathered.append(program_index_all)

    return all_dataset, index_set_completely_gathered, program_index_all, complet_num


def dictionary_parse(all_dataset):
    opcodelistdir = 'E:\\All_code\\Datasets\\fullRawOpCodeList.txt'
    with open(opcodelistdir, 'r') as file:
        list_opcode = [opcodes[:-1] for opcodes in file]
    transformed_dataset = [dictionary_mapping(instance, list_opcode) for instance in all_dataset]
    print(list_opcode)
    return transformed_dataset


def dictionary_mapping(instance, list_opcode):
    listtotransform = []
    for opcode in instance:
        try:
            listtotransform.append(list_opcode.index(opcode))
        except ValueError:
            print('opcode_not_found = ' + str(opcode))
            listtotransform.append(-1)
    return listtotransform


def get_unique_opcodes(all_dataset):
    unique_ins = []
    for instance in all_dataset:
        unique_ins.extend(list(set(instance)))
    final_unique_ins = list(set(unique_ins))
    print(final_unique_ins)


def assert_size(all_dataset):
    return all([len(instance) == 1000 for instance in all_dataset])


def write_to_csv(dataset, dir_to_write):
    with open(dir_to_write, 'w', newline='') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',',
                                quotechar=' ', quoting=csv.QUOTE_ALL)
        spamwriter.writerows(dataset)


if __name__ == "__main__":
    # Raw runtrace file produced by debugger
    raw_runtrace_file = "D:\\bigproject_repository\\rtrace_new_malware.txt"
    all_dataset, index_set_completely_gathered, program_index_all, complet_num = parse(
        raw_runtrace_file=raw_runtrace_file)
    print('program_index_all  = ' + str(program_index_all))
    print('thousand_gathered_number  = ' + str(complet_num))
    print('index_set_completely_gathered = ' + str(index_set_completely_gathered) + ' length = ' + str(
        len(index_set_completely_gathered)))
    assert (assert_size(all_dataset)), 'Invalid length'
    transdata = dictionary_parse(all_dataset)
    # Dir of csv file to write final parsed dataset
    dirofmaincsv = 'D:\\bigproject_repository\\final_benign\\external_malware.csv'
    write_to_csv(transdata, dirofmaincsv)
    get_unique_opcodes(all_dataset)

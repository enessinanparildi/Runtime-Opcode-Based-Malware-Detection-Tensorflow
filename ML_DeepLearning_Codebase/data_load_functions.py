import opcode_embeddings
import numpy as np
import helper_functions
import preprocessing
from sklearn.model_selection import train_test_split

numpy_data_root_dir = 'E:\\All_code\\ML_DeepLearning_Codebase\\saveddata\\Fixed_numpy_dataset'
embedding_mat_root_dir = 'E:\\All_code\\ML_DeepLearning_Codebase\\saveddata\\Embedding_matrix'
raw_data_root_dir = 'E:\\All_code\\Datasets\\'


def load_data_v3_all_mixed_final_version(include_artificial=False, load_larger_test=False, modify_opcode=False,
                                         auto_encoder_data=False):
    if include_artificial:
        name = 'artificial_included'
        train_data = np.load(
            numpy_data_root_dir + "\\train_data_v3" + name + ".npy")
        train_label = np.load(
            numpy_data_root_dir + "\\train_label_v3" + name + ".npy")
        test_data = np.load(
            numpy_data_root_dir + "\\test_data_v3" + name + ".npy")
        test_label = np.load(
            numpy_data_root_dir + "\\test_label_v3" + name + ".npy")
    elif load_larger_test:
        name = "_test_size=0.5"
        name2 = 'artificial_non_included'
        train_data = np.load(
            numpy_data_root_dir + "\\train_data_v3" + name + name2 + ".npy")
        train_label = np.load(
            numpy_data_root_dir + "\\train_label_v3" + name + name2 + ".npy")
        test_data = np.load(
            numpy_data_root_dir + "\\test_data_v3" + name + name2 + ".npy")
        test_label = np.load(
            numpy_data_root_dir + "\\test_label_v3" + name + name2 + ".npy")
    else:
        name = 'artificial_non_included'
        train_data = np.load(
            numpy_data_root_dir + "\\train_data_v3" + name + ".npy")
        train_label = np.load(
            numpy_data_root_dir + "\\train_label_v3" + name + ".npy")
        test_data = np.load(
            numpy_data_root_dir + "\\test_data_v3" + name + ".npy")
        test_label = np.load(
            numpy_data_root_dir + "\\test_label_v3" + name + ".npy")
        print('length_train_data = ' + str(len(train_data)))
        print('length_test_data = ' + str(len(test_data)))

    class_weight = helper_functions.get_class_weight_for_cross_entropy_loss(train_label)
    print('class weight = ' + str(class_weight))

    if auto_encoder_data:
        dictionary = np.load(
            embedding_mat_root_dir + "\\gensim_v6_new_benign_dict.npy")
        embedding_mat = np.load(
            embedding_mat_root_dir + "\\gensim_v6_new_benign_.npy")
    else:
        embedding_mat = np.load(
            embedding_mat_root_dir + " \\gensim_v7_new_benign_unk_token.npy")
        dictionary = np.load(
            embedding_mat_root_dir + "\\gensim_v7_new_benign_dict_unk_token.npy")

    opcode_embeddings.whole_opcode_preprocessing_ops(train_data)
    opcode_embeddings.whole_opcode_preprocessing_ops(test_data)

    print('converted')
    print(np.where(train_data == 471))
    print(np.where(test_data == 471))
    print(np.where(train_data == 291))
    print(np.where(test_data == 291))
    print(np.where(train_data == 270))
    print(np.where(test_data == 270))

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)

    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, dictionary, class_weight


def load_data(use_imbalanced=False):
    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\'
    if not use_imbalanced:
        train_data = np.load(
            root_dir + "\\train_data.npy")
        train_label = np.load(
            root_dir + "\\train_label.npy")
        test_data = np.load(
            root_dir + "\\test_data.npy")
        test_label = np.load(
            root_dir + "\\test_label.npy")
    else:
        train_data = np.load(
            root_dir + "train_data_imbalanced.npy")
        train_label = np.load(
            root_dir + "\\train_label_imbalanced.npy")
        test_data = np.load(
            root_dir + "\\test_data_imbalanced.npy")
        test_label = np.load(
            root_dir + "\\test_label_imbalanced.npy")
    #
    # print(len(train_label) + len(test_label))
    # print(len(np.where(train_label==0)[0]) + len(np.where(test_label==0)[0]))
    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_.npy")

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)
    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, dictionary, None


def prapare_data_v3():
    wholeseq_real_data, wholeseq_real_labels, seqnewbenigndata, seqnewbenignlabels = opcode_embeddings.get_dataset_v2()

    X_train, X_test, y_train, y_test = train_test_split(wholeseq_real_data, wholeseq_real_labels, test_size=0.4)

    X_train_complete = np.concatenate((X_train, seqnewbenigndata))
    y_train_complete = np.concatenate((y_train, seqnewbenignlabels))

    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks'

    np.save(root_dir + "\\train_data_v2.npy", X_train_complete)
    np.save(root_dir + "\\train_label_v2.npy", y_train_complete)
    np.save(root_dir + "\\test_data_v2.npy", X_test)
    np.save(root_dir + "\\test_label_v2.npy", y_test)


def load_data_v_predict_only_new_benign(modify_opcode=False, load_artifical_included=False):
    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\'

    if load_artifical_included:
        name = 'artificial_included'
        train_data = np.load(
            root_dir + "\\train_data_v_predict_only_new_benign" + name + ".npy")
        train_label = np.load(
            root_dir + "\\train_label_v_predict_only_new_benign" + name + ".npy")
        test_data = np.load(
            root_dir + "\\test_data_v_predict_only_new_benign" + name + ".npy")
        test_label = np.load(
            root_dir + "\\test_label_v__predict_only_new_benign" + name + ".npy")
    else:
        name = 'artificial_non_included'
        train_data = np.load(
            root_dir + "\\train_data_v_predict_only_new_benign" + name + ".npy")
        train_label = np.load(
            root_dir + "\\train_label_v_predict_only_new_benign" + name + ".npy")
        test_data = np.load(
            root_dir + "\\test_data_v_predict_only_new_benign" + name + ".npy")
        test_label = np.load(
            root_dir + "\\test_label_v__predict_only_new_benign" + name + ".npy")

    print('length_train_data = ' + str(len(train_data)))
    print('length_test_data = ' + str(len(test_data)))

    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_.npy")

    if modify_opcode:
        np.place(train_data, train_data == 270, 262)
        np.place(test_data, test_data == 270, 262)

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)

    converted_test_data = np.int32(converted_test_data)

    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, dictionary, None


def sample_of_2000_trial():
    wholeseq_real_data, wholeseq_real_labels, seqnewbenigndata, seqnewbenignlabels = opcode_embeddings.get_dataset_v2()
    whole_new_benign = opcode_embeddings.get_dataset_new_benign()
    new_benign_labels = np.zeros(len(whole_new_benign))

    malware_part_of_data = wholeseq_real_data[np.where(wholeseq_real_labels == 1)[0], :]
    malware_part_of_labels = wholeseq_real_labels[np.where(wholeseq_real_labels == 1)[0]]

    benign_part_of_data = wholeseq_real_data[np.where(wholeseq_real_labels == 0)[0], :]
    benign_part_of_labels = wholeseq_real_labels[np.where(wholeseq_real_labels == 0)[0]]

    fake_class1_samples = np.concatenate((malware_part_of_data[:1, :], benign_part_of_data[:]))
    fake_class0_samples = whole_new_benign[:7000]
    all_data = np.concatenate((fake_class1_samples, fake_class0_samples))
    all_labels = np.concatenate((np.ones(len(fake_class1_samples)), np.zeros(len(fake_class0_samples))))
    # all_data = whole_new_benign[:2000]
    # all_labels = np.random.randint(2, size=len(all_data))

    train_data, test_data, train_label, test_label = train_test_split(all_data,
                                                                      all_labels, test_size=0.3, random_state=42)
    print(test_label)

    print('length_train_data = ' + str(len(train_data)))
    print('length_test_data = ' + str(len(test_data)))

    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_.npy")

    np.place(train_data, train_data == 270, 262)
    np.place(test_data, test_data == 270, 262)

    opcode_embeddings.convert_opcode_for_rep_series_prefix(train_data)
    opcode_embeddings.convert_opcode_for_rep_series_prefix(test_data)
    opcode_embeddings.convert_opcode_for_lock_series_prefix(train_data)
    opcode_embeddings.convert_opcode_for_lock_series_prefix(test_data)
    print('converted')
    print(np.where(train_data == 471))
    print(np.where(test_data == 471))
    print(np.where(train_data == 291))
    print(np.where(test_data == 291))

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)

    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, dictionary, None


# There are three different batches of new malware load_new_malware load_new_malware_v2 load_new_malware_v3
def load_new_malware():
    path = raw_data_root_dir + "\\external_malware.csv"
    new_external_malware, labels = opcode_embeddings.get_external_malware_all(path)

    dictionary = np.load(
        embedding_mat_root_dir + " \\gensim_v7_new_benign_dict_unk_token.npy")
    labels = np.ones((len(new_external_malware)))
    opcode_embeddings.whole_opcode_preprocessing_ops(new_external_malware)
    converted_new_external_malware = opcode_embeddings.convert_dictionary_values(new_external_malware, dictionary)
    return converted_new_external_malware, labels


def load_new_malware_v2():
    path = raw_data_root_dir + "\\external_malware_v2.csv"
    new_external_malware, labels = opcode_embeddings.get_external_malware_all(path)
    dictionary = np.load(
        embedding_mat_root_dir + " \\gensim_v7_new_benign_dict_unk_token.npy")
    labels = np.ones((len(new_external_malware)))
    opcode_embeddings.whole_opcode_preprocessing_ops(new_external_malware)
    converted_new_external_malware = opcode_embeddings.convert_dictionary_values(new_external_malware, dictionary)
    return converted_new_external_malware, labels


def load_new_malware_v3():
    path = raw_data_root_dir + "\\external_malware_v3.csv"
    new_external_malware, labels = opcode_embeddings.get_external_malware_all(path)
    dictionary = np.load(
        embedding_mat_root_dir + " \\gensim_v7_new_benign_dict_unk_token.npy")
    labels = np.ones((len(new_external_malware)))
    opcode_embeddings.whole_opcode_preprocessing_ops(new_external_malware)
    converted_new_external_malware = opcode_embeddings.convert_dictionary_values(new_external_malware, dictionary)
    return converted_new_external_malware, labels


def prapare_data_v_predict_only_new_benign(include_artificial_benign_to_train=False):
    wholeseq_real_data, wholeseq_real_labels, seqnewbenigndata, seqnewbenignlabels = opcode_embeddings.get_dataset_v2()
    whole_new_benign = opcode_embeddings.get_dataset_new_benign()
    new_benign_labels = np.zeros(len(whole_new_benign))

    malware_part_of_data = wholeseq_real_data[np.where(wholeseq_real_labels == 1)[0], :]
    malware_part_of_labels = wholeseq_real_labels[np.where(wholeseq_real_labels == 1)[0]]

    malx_train, malx_test, maly_train, maly_test = train_test_split(malware_part_of_data,
                                                                    malware_part_of_labels, test_size=0.5)

    X_train = np.concatenate((malx_train, wholeseq_real_data[np.where(wholeseq_real_labels == 0)[0], :]))
    X_test = np.concatenate((malx_test, whole_new_benign))
    y_train = np.concatenate((maly_train, wholeseq_real_labels[np.where(wholeseq_real_labels == 0)[0]]))
    y_test = np.concatenate((maly_test, new_benign_labels))

    inds = np.arange(len(X_train))
    np.random.shuffle(inds)
    X_train = X_train[inds, :]
    y_train = y_train[inds]

    print('length_x_train = ' + str(len(X_train)))
    print('length_x_test = ' + str(len(X_test)))
    print('length_y_train = ' + str(len(y_train)))
    print('length_y_test  = ' + str(len(y_test)))

    print('length_y_train_label1 = ' + str(len(np.where(y_train == 1)[0])))
    print('length_y_train_label0 = ' + str(len(np.where(y_train == 0)[0])))

    name = 'artificial_non_included'

    if include_artificial_benign_to_train:
        seqnewbenigndatasection = seqnewbenigndata[:8600, :]
        seqnewbenignlabelssection = seqnewbenignlabels[:8600]
        X_train = np.concatenate((X_train, seqnewbenigndatasection))
        y_train = np.concatenate((y_train, seqnewbenignlabelssection))
        name = 'artificial_included'

    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks'

    np.save(root_dir + "\\train_data_v_predict_only_new_benign" + name + ".npy", X_train)
    np.save(root_dir + "\\train_label_v_predict_only_new_benign" + name + ".npy", y_train)
    np.save(root_dir + "\\test_data_v_predict_only_new_benign" + name + ".npy", X_test)
    np.save(root_dir + "\\test_label_v__predict_only_new_benign" + name + ".npy", y_test)


def prapare_data_v4_all_mixed(include_artificial_benign_to_train=False):
    wholeseq_real_data, wholeseq_real_labels, seqnewbenigndata, seqnewbenignlabels = opcode_embeddings.get_dataset_v2()
    whole_new_benign = opcode_embeddings.get_dataset_new_benign()
    new_benign_labels = np.zeros(len(whole_new_benign))

    wholeseq_real_data_with_new_benign = np.concatenate((wholeseq_real_data, whole_new_benign))
    wholeseq_real_labels_with_new_benign = np.concatenate((wholeseq_real_labels, new_benign_labels))

    inds = np.arange(len(wholeseq_real_data_with_new_benign))
    np.random.shuffle(inds)
    wholeseq_real_data_with_new_benign = wholeseq_real_data_with_new_benign[inds, :]
    wholeseq_real_labels_with_new_benign = wholeseq_real_labels_with_new_benign[inds]

    X_train, X_test, y_train, y_test = train_test_split(wholeseq_real_data_with_new_benign,
                                                        wholeseq_real_labels_with_new_benign, test_size=0.4)

    print('length_x_train = ' + str(len(X_train)))
    print('length_x_test = ' + str(len(X_test)))
    print('length_y_train = ' + str(len(y_train)))
    print('length_y_test  = ' + str(len(y_test)))

    name = 'artificial_non_included'

    if include_artificial_benign_to_train:
        X_train = np.concatenate((X_train, seqnewbenigndata))
        y_train = np.concatenate((y_train, seqnewbenignlabels))
        name = 'artificial_included'

    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks'

    np.save(root_dir + "\\train_data_v3_test_size=0.5" + name + ".npy", X_train)
    np.save(root_dir + "\\train_label_v3_test_size=0.5" + name + ".npy", y_train)
    np.save(root_dir + "\\test_data_v3_test_size=0.5" + name + ".npy", X_test)
    np.save(root_dir + "\\test_label_v3_test_size=0.5" + name + ".npy", y_test)


def load_new_benign_data():
    whole_data = opcode_embeddings.get_dataset_new_benign()
    labels = np.zeros(len(whole_data))

    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_.npy")

    converted_data = opcode_embeddings.convert_dictionary_values(whole_data, dictionary)

    return converted_data, labels, embedding_mat, dictionary


def load_data_v2():
    root_dir = 'D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\'

    train_data = np.load(
        root_dir + "\\train_data_v2.npy")
    train_label = np.load(
        root_dir + "\\train_label_v2.npy")
    test_data = np.load(
        root_dir + "\\test_data_v2.npy")
    test_label = np.load(
        root_dir + "\\test_label_v2.npy")

    class_weight = helper_functions.get_class_weight_for_cross_entropy_loss(train_label)
    print('class weight = ' + str(class_weight))

    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v5_new_benign_.npy")

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)

    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, dictionary, class_weight


def prapare_data_v2(use_imbalanced):
    train_data, train_label, test_data, test_label, embedding_mat, dictionary, class_weight = load_data(use_imbalanced)

    class_weight = helper_functions.get_class_weight_for_cross_entropy_loss(train_label)
    print('class weight = ' + str(class_weight))

    one_hot_batch_train_label = helper_functions.one_hot_coder(train_label.reshape(-1, 1))
    one_hot_batch_test_label = helper_functions.one_hot_coder(test_label.reshape(-1, 1))

    dictionary = np.load(
        "C:\\Users\\Ben\\Google Drive\\bigproject\\codes\\saveddata\\Embedding_matrix_networks\\gensim_v4_dict.npy")
    embedding_mat = np.load(
        "C:\\Users\\Ben\\Google Drive\\bigproject\\codes\\saveddata\\Embedding_matrix_networks\\gensim_v4.npy")

    return train_data, train_label, test_data, test_label, \
           one_hot_batch_train_label, one_hot_batch_test_label, \
           dictionary, embedding_mat, class_weight


def prapare_data(use_imbalanced):
    train_data, train_label, test_data, test_label, embedding_mat, dictionary, class_weight = load_data(use_imbalanced)
    class_weight = helper_functions.get_class_weight_for_cross_entropy_loss(train_label)
    print('class weight = ' + str(class_weight))

    # one_hot_batch_train_label = one_hot_coder(train_label.reshape(-1, 1))
    # one_hot_batch_test_label = one_hot_coder(test_label.reshape(-1, 1))

    dictionary = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v4_dict.npy")
    embedding_mat = np.load(
        "D:\\thesis_code_base\\saveddata\\Embedding_matrix_networks\\gensim_v4.npy")

    converted_train_data = opcode_embeddings.convert_dictionary_values(train_data, dictionary)
    converted_test_data = opcode_embeddings.convert_dictionary_values(test_data, dictionary)

    return converted_train_data, train_label, converted_test_data, test_label, embedding_mat, class_weight


def load_freq_dataset():
    frequency_data_dir = "C:\\Users\\Ben\\Google Drive\\bigproject\\dataset\\all_malware_benign_master.csv"
    frequency_data, frequency_datalabels, frequency_numberlabels, uniquelabels, classsizes = \
        preprocessing.process_data_v2(frequency_data_dir)
    binary_labels = np.ones(len(frequency_numberlabels))
    binary_labels[np.where(np.array(frequency_numberlabels) == 3)[0]] = 0
    inds = np.arange(len(frequency_numberlabels))
    np.random.shuffle(inds)
    inds.astype(np.int_)
    print(inds)
    return frequency_data[inds, :], np.array(frequency_numberlabels)[inds], binary_labels[inds]


def load_freq_dataset_newcrypto(subset_size):
    frequency_data_dir = 'C:\\Users\\Ben\\Google Drive\\bigproject\\dataset\\second_dataset\\allCrypto_fulltraces.csv'
    frequency_data, frequency_datalabels, frequency_numberlabels, uniquelabels, classsizes = \
        preprocessing.process_data_v2(frequency_data_dir)
    return frequency_data[:subset_size], 16 * np.ones(subset_size)


def prapare_new_data():
    seq_data, labels = opcode_embeddings.get_dataset()
    train_data, train_label, test_data, test_label = opcode_embeddings.test_train_split(seq_data, labels)
    return train_data, train_label, test_data, test_label
